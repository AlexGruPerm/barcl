
spark-shell --driver-memory 3G --executor-memory 5G  --executor-cores 1 --jars "/opt/spark-2.3.2/jars/spark-cassandra-connector-assembly-2.3.2.jar" --conf "spark.cassandra.connection.host=192.168.122.192"

import org.apache.spark.sql._
import org.apache.spark.sql.functions.round
import org.apache.spark.sql.cassandra._
import com.datastax.spark.connector._
import org.apache.spark.sql.types.{DoubleType}
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.ml.linalg.{DenseVector,SparseVector}
import org.apache.spark.ml.classification.MultilayerPerceptronClassifier
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import spark.implicits._

case class FormKeys(ticker_id     :Int,
                    bar_width_sec :Int)

case class Form(ticker_id     :Int,
                bar_width_sec :Int,
                ts_begin      :Long,
                ts_end        :Long,
                log_oe        :Double,
                res_type      :String,
                formdeepkoef  :Int,
                frmconfpeak   :Int,
                sps           :Double,
                sms           :Double,
                tcvolprofile  :Int
                )

case class ccLibSvm(label    :Int,
                    features :Int)

 def getKeysFormsDb(BarWidthSec: Int) :Dataset[FormKeys] = {
            import org.apache.spark.sql.functions._
            spark.read.format("org.apache.spark.sql.cassandra")
              .options(Map("table" -> "bars_forms", "keyspace" -> "mts_bars"))
              .load()
              .where(col("bar_width_sec") === BarWidthSec)
              .select(
                col("ticker_id"),
                col("bar_width_sec")
                ).distinct.sort(asc("ticker_id"),asc("bar_width_sec")).as[FormKeys]}

val dsKeys = getKeysFormsDb(600);
dsKeys.show()

 def getFormsDb(TickerID :Int, BarWidthSec: Int) :Dataset[Form] = {
            import org.apache.spark.sql.functions._
            spark.read.format("org.apache.spark.sql.cassandra")
              .options(Map("table" -> "bars_forms", "keyspace" -> "mts_bars"))
              .load()
              .where(col("ticker_id") === TickerID)
              .where(col("bar_width_sec") === BarWidthSec)
              .select(
                col("ticker_id"),
                col("bar_width_sec"),
                col("ts_begin"),
                col("ts_end"),
                col("log_oe"),
                col("res_type"),
                col("formdeepkoef"),
                col("formprops")("frmconfpeak").as("frmconfpeak").cast("Int"),
                col("formprops")("sps").as("sps").cast("Double"),
                col("formprops")("sms").as("sms").cast("Double"),
                col("formprops")("tcvolprofile").as("tcvolprofile").cast("Int")
                ).sort(asc("ticker_id"),asc("bar_width_sec"),asc("ts_begin")).as[Form]}

val seqDsForms :Seq[Dataset[Form]] = dsKeys.collect.toSeq.map(elm => getFormsDb(elm.ticker_id,elm.bar_width_sec))
val ds :Dataset[Form] = seqDsForms.reduce(_ union _)
ds.cache()
ds.count()

//====================================================================================================================

val mlsrc = ds.withColumn("label",
   when($"res_type" === "mx", 1).otherwise(
    when($"res_type" === "mn", 2).otherwise(3))).
     select(
      col("label").cast(DoubleType),
      col("frmconfpeak"),
      col("sps"),
      col("sms"),
      col("tcvolprofile")
     ).withColumn("f1", round(col("frmconfpeak")/100)).withColumn("f2", round((col("frmconfpeak") - round(col("frmconfpeak")/100)*100)/10)).withColumn("f3", col("frmconfpeak") % 10)

val clr = mlsrc
val assembler = new VectorAssembler().setInputCols(Array("f1","f2","f3","sps","sms","tcvolprofile")).setOutputCol("features")
val dat = assembler.transform(clr)
val data = dat.drop("f1").drop("f2").drop("f3").drop("sps").drop("sms").drop("tcvolprofile")
val splits = data.randomSplit(Array(0.6, 0.4), seed = 1234L)
val train = splits(0)
val test = splits(1)
println(" rows:"+data.count()+" train:"+train.count()+" test:"+test.count())

//====================================================================================================================

val layers = Array[Int](6, 10, 5, 3)
val trainer = new MultilayerPerceptronClassifier().setLayers(layers).setLabelCol("label").setFeaturesCol("features").setBlockSize(128).setSeed(1234L).setMaxIter(100)
val model = trainer.fit(train)
val result = model.transform(test)
val predictionAndLabels = result.select("prediction", "label")
val evaluator = new MulticlassClassificationEvaluator().setMetricName("accuracy")
println(s"Test set accuracy = ${evaluator.evaluate(predictionAndLabels)}")

Test set accuracy = 0.5149456521739131 - without
Test set accuracy = 0.5136054421768708 - with tcvolprofile

//====================================================================================================================

// recreate model on full Dataset

val layers = Array[Int](6, 10, 5, 3)
val trainer = new MultilayerPerceptronClassifier().setLayers(layers).setLabelCol("label").setFeaturesCol("features").setBlockSize(128).setSeed(1234L).setMaxIter(100)
val model = trainer.fit(data)
val result = model.transform(data) //on full data
val predictionAndLabels = result.select("prediction", "label")
val evaluator = new MulticlassClassificationEvaluator().setMetricName("accuracy")
println(s"Test set accuracy = ${evaluator.evaluate(predictionAndLabels)}")

Test set accuracy = 0.5610939567710631 //на полном наборе данных!

spark.catalog.dropGlobalTempView("tmp")
result.createGlobalTempView("tmp")
spark.sql(""" select * from global_temp.tmp """)


OK
scala> spark.sql(""" select sum(1) as cnt from global_temp.tmp where label=prediction""").show
+----+
| cnt|
+----+
|1272| 4*300
+----+

WRONG
scala> spark.sql(""" select sum(1) as cnt from global_temp.tmp where label!=prediction""").show
+---+
|cnt|
+---+
|995| 3*300
+---+

на 25% больше правильно предсказанных точек по полному набору данных.